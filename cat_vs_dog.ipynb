{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "aI8tCwAhnY2I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import UnidentifiedImageError, Image\n",
        "from keras import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgjIVY9HyHR9",
        "outputId": "d2ff3444-8814-42b1-83a6-cc77312e7b4a"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir='/content/drive/MyDrive/data/train'\n",
        "test_dir='/content/drive/MyDrive/data/test'"
      ],
      "metadata": {
        "id": "_CTupnhNyqMw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "x7cxgSjE1LZX"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds=train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=32,\n",
        "    target_size=(256,256),\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVeiqv5T1aSX",
        "outputId": "b600608a-c2e9-477c-f15f-1f317d016c31"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds=test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    batch_size=32,\n",
        "    target_size=(256,256),\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGbOKi5v68QP",
        "outputId": "9800a07c-00df-46fd-f0fa-5ab076f2d741"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 60 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images,labels=next(train_ds)"
      ],
      "metadata": {
        "id": "imPwiSI4J_HY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout"
      ],
      "metadata": {
        "id": "3-Tq1kDeAT0K"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AlexNet(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        # 1st Convolutional Layer\n",
        "        Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=input_shape),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        # 2nd Convolutional Layer\n",
        "        Conv2D(filters=256, kernel_size=(5,5), padding='same', activation='relu'),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        # 3rd Convolutional Layer\n",
        "        Conv2D(filters=384, kernel_size=(3,3), padding='same', activation='relu'),\n",
        "\n",
        "        # 4th Convolutional Layer\n",
        "        Conv2D(filters=384, kernel_size=(3,3), padding='same', activation='relu'),\n",
        "\n",
        "        # 5th Convolutional Layer\n",
        "        Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu'),\n",
        "        MaxPooling2D(pool_size=(3,3), strides=(2,2)),\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        Flatten(),\n",
        "        Dense(units=4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(units=4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # Output Layer\n",
        "        Dense(units=1, activation='sigmoid')  # For binary classification\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(),  # Optimizer\n",
        "                  loss='binary_crossentropy',  # Loss function\n",
        "                  metrics=['accuracy'])  # List of metrics to evaluate\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "input_shape = (256, 256, 3)\n",
        "num_classes = 2\n",
        "\n",
        "# Create an instance of the AlexNet model\n",
        "model = AlexNet(input_shape, num_classes)"
      ],
      "metadata": {
        "id": "wk0snsRt_5at"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=10, validation_data=test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MggIsQ17B2p0",
        "outputId": "5ca1b5e2-7858-4140-f8d8-2823e310aa9a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 32s 7s/step - loss: 2.4869 - accuracy: 0.5500 - val_loss: 0.6933 - val_accuracy: 0.4833\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 27s 8s/step - loss: 0.7165 - accuracy: 0.5000 - val_loss: 0.6956 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 27s 7s/step - loss: 0.7009 - accuracy: 0.5000 - val_loss: 0.7025 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 29s 9s/step - loss: 0.6966 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 26s 6s/step - loss: 0.6947 - accuracy: 0.4200 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 26s 7s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6936 - val_accuracy: 0.5000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 27s 6s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6939 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 27s 7s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6946 - val_accuracy: 0.5000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 26s 7s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6955 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 27s 8s/step - loss: 0.6950 - accuracy: 0.5000 - val_loss: 0.6952 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(test_ds)\n",
        "print(f'test loss: {loss}')\n",
        "print(f'test accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvqH5TFjFNMZ",
        "outputId": "4ba934bd-604e-4601-8466-3768c1a9aa25"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 3s 1s/step - loss: 0.7344 - accuracy: 0.4500\n",
            "test loss: 0.7343852519989014\n",
            "test accuracy: 0.44999998807907104\n"
          ]
        }
      ]
    }
  ]
}